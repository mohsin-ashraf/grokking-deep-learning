{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mohsin/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf # Used for Loading Datasets.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, true), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train,x_test = x_train/255.0 ,x_test/255.0\n",
    "inputs = x_train.reshape(x_train.shape[0],784)\n",
    "test = x_test.reshape(x_test.shape[0],784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs Shape (60000, 784)\n",
      "True Shape (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "test_true = pd.get_dummies(y_test).values\n",
    "true = pd.get_dummies(true).values\n",
    "print (\"Inputs Shape {}\".format(inputs.shape))\n",
    "print (\"True Shape {}\".format(true.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x>0)*x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output > 0\n",
    "\n",
    "def sigmoid(x) : \n",
    "    return 1 / (1 + np.e**(-x))\n",
    "def sigmoid_deriv(x): \n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0_1 = 2 * np.random.random((784,hidden_size)) - 1\n",
    "weights_1_2 = 2 * np.random.random((hidden_size,10)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:36<00:00, 1625.35it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:0 Test-Err:0.045 Test-Acc:0.866 Train-Err:0.636 Train-Acc:0.705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:37<00:00, 1606.41it/s]\n",
      "100%|██████████| 60000/60000 [00:35<00:00, 1671.26it/s]\n",
      "100%|██████████| 60000/60000 [00:38<00:00, 1553.08it/s]\n",
      "100%|██████████| 60000/60000 [00:38<00:00, 1562.03it/s]\n",
      "100%|██████████| 60000/60000 [00:39<00:00, 1533.18it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:5 Test-Err:0.032 Test-Acc:0.915 Train-Err:0.401 Train-Acc:0.833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:34<00:00, 1719.84it/s]\n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1730.97it/s]\n",
      "100%|██████████| 60000/60000 [00:33<00:00, 1766.34it/s]\n",
      " 95%|█████████▌| 57012/60000 [00:32<00:01, 1761.14it/s]/home/mohsin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in power\n",
      "  \n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1743.10it/s]\n",
      "100%|██████████| 60000/60000 [00:35<00:00, 1713.90it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:10 Test-Err:0.027 Test-Acc:0.927 Train-Err:0.371 Train-Acc:0.849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:34<00:00, 1717.27it/s]\n",
      "100%|██████████| 60000/60000 [00:33<00:00, 1767.29it/s]\n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1735.85it/s]\n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1728.94it/s]\n",
      "100%|██████████| 60000/60000 [00:35<00:00, 1675.48it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:15 Test-Err:0.030 Test-Acc:0.922 Train-Err:0.370 Train-Acc:0.853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:34<00:00, 1729.99it/s]\n",
      "100%|██████████| 60000/60000 [00:35<00:00, 1703.11it/s]\n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1756.86it/s]\n",
      "100%|██████████| 60000/60000 [00:34<00:00, 1739.49it/s]\n",
      "100%|██████████| 60000/60000 [00:33<00:00, 1779.25it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:20 Test-Err:0.030 Test-Acc:0.931 Train-Err:0.368 Train-Acc:0.854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:34<00:00, 1738.65it/s]\n",
      "100%|██████████| 60000/60000 [00:33<00:00, 1767.83it/s]\n",
      "100%|██████████| 60000/60000 [00:38<00:00, 1569.66it/s]\n",
      "100%|██████████| 60000/60000 [00:42<00:00, 1413.79it/s]\n",
      "100%|██████████| 60000/60000 [00:42<00:00, 1406.81it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:25 Test-Err:0.028 Test-Acc:0.923 Train-Err:0.373 Train-Acc:0.854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:37<00:00, 1592.97it/s]\n",
      "100%|██████████| 60000/60000 [00:35<00:00, 1670.72it/s]\n",
      "100%|██████████| 60000/60000 [00:40<00:00, 1479.56it/s]\n",
      "100%|██████████| 60000/60000 [00:40<00:00, 1497.13it/s]\n",
      "100%|██████████| 60000/60000 [00:43<00:00, 1373.76it/s]\n",
      "  0%|          | 0/60000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I:30 Test-Err:0.035 Test-Acc:0.912 Train-Err:0.343 Train-Acc:0.865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60000/60000 [00:43<00:00, 1383.94it/s]\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(inputs)))\n",
    "for iteration in range(32):\n",
    "    correct_pct = 0\n",
    "    layer_2_error = 0\n",
    "    np.random.shuffle(indices)\n",
    "    inputs = inputs[indices]\n",
    "    true = true[indices]\n",
    "    for i in tqdm(range(len(inputs))):\n",
    "        layer_0 = inputs[i:i+1]\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        dropout_mask = np.random.randint(2, size=layer_1.shape)\n",
    "        layer_1 *= dropout_mask * 2\n",
    "        layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "        \n",
    "        layer_2_error += np.sum((layer_2 - true[i:i+1]) ** 2)\n",
    "        correct_pct += int(np.argmax(layer_2) == np.argmax(true[i:i+1]))\n",
    "        \n",
    "        layer_2_delta = (layer_2 - true[i:i+1]) * sigmoid_deriv(layer_2)\n",
    "        layer_1_delta = np.dot(layer_2_delta,weights_1_2.T) * relu2deriv(layer_1)\n",
    "        \n",
    "        weights_1_2 -= alpha * np.dot(layer_1.T,layer_2_delta)\n",
    "        weights_0_1 -= alpha * np.dot(layer_0.T,layer_1_delta)\n",
    "        \n",
    "        \n",
    "    if iteration % 5 == 0:\n",
    "        test_error = 0\n",
    "        test_correct_pct = 0\n",
    "        for test_iteration in range(len(x_test)):\n",
    "            layer_0 = x_test[test_iteration:test_iteration+1].reshape(784)\n",
    "            layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "            layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "            test_error += np.sum((test_true[test_iteration:test_iteration+1] - layer_2)**2)\n",
    "            test_correct_pct += np.argmax(layer_2) == np.argmax(test_true[test_iteration: test_iteration+1])\n",
    "        sys.stdout.write(\"\\n\" + \"I:\" + str(iteration) + \" Test-Err:\" + str(test_error/ float(len(x_train)))[0:5] + \\\n",
    "            \" Test-Acc:\" + str(test_correct_pct/ float(len(x_test)))[0:5]+ \" Train-Err:\" + str(layer_2_error/ float(len(x_train)))[0:5] +\\\n",
    "            \" Train-Acc:\" + str(correct_pct/ float(len(x_train)))[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(layer_0):\n",
    "    layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "    layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "    return np.argmax(layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 6\n",
      "True label: 6\n"
     ]
    }
   ],
   "source": [
    "sample_no = 123\n",
    "print (f\"Prediction: {predict_sample(x_test[sample_no].reshape(784))}\")\n",
    "print (f\"True label: {np.argmax(test_true[sample_no])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
